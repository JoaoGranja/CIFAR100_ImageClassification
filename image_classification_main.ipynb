{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image_classification_main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/JoaoGranja/CIFAR10_ImageClassification/blob/master/image_classification_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"fug7eGzTzLbg","executionInfo":{"status":"ok","timestamp":1630144147003,"user_tz":-60,"elapsed":304,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}}},"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","is_colab = True"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6PycgYA0ppQa"},"source":["\n","# **Colab Preparation** \n","Before handling the project, we need to install tensorflow/keras and pip packages. I also share my google drive to simplify the connection with my google drive account.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8j5egONdppQb","executionInfo":{"status":"ok","timestamp":1630144169417,"user_tz":-60,"elapsed":22199,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}},"outputId":"271f7519-9587-4818-86fd-58f2bc26cc1d"},"source":["if is_colab:\n","    #Package Installation and share Google Drive\n","    !pip install --upgrade pip\n","    #!pip install --upgrade keras\n","    !pip install keras-resnet\n","    !pip install tensorflow==2.6.0\n","    !pip install tensorflow-gpu==2.6.0\n","    #!pip install --upgrade tensorflow_hub\n","    !pip install tensorflow_addons\n","    !pip install keras==2.6\n","\n","    !pip install --quiet vit-keras\n","\n","\n","    from google.colab import drive\n","    drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.2.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: keras-resnet in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet) (2.6.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: tensorflow==2.6.0 in /usr/local/lib/python3.7/dist-packages (2.6.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.19.5)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.12.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.12)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.2)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.39.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.6.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.7.4.3)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (5.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.37.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.6.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.3.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.2.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.1.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.4.0)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.6.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.6.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.12.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.17.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.0) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.34.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.3.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.5)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.6.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2021.5.30)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.5.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: tensorflow-gpu==2.6.0 in /usr/local/lib/python3.7/dist-packages (2.6.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (5.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (0.37.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.6.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (3.3.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.12)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (2.6.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (2.6.0)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (2.6.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.19.5)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (0.12.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.12.1)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (0.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.39.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (3.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (3.17.3)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.15.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (3.7.4.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (1.1.2)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0) (0.2.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-gpu==2.6.0) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (3.3.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (1.34.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.4.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.6.0) (4.6.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.6.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.6.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.6.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.6.0) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.6.0) (3.5.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: keras==2.6 in /usr/local/lib/python3.7/dist-packages (2.6.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NToyjnZ4Uc2k"},"source":[" # **Configuration and imports**\n","\n","The first thing I do is to import all modules we need for this project. I also use some configuration parameters to provide more flexibility to the tranining process\n","\n","In this project I will be making use of the Keras library for creating our model and training it. I will also use Matplotlib for visualizing our dataset to gain a better understanding of the images we are going to be handling.\n","\n"]},{"cell_type":"code","metadata":{"id":"Rk78b8REzLbl","executionInfo":{"status":"ok","timestamp":1630144171707,"user_tz":-60,"elapsed":2296,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}}},"source":["# Generic Imports\n","import time\n","import gc\n","import logging, os\n","import sys\n","import random\n","import warnings\n","import pickle\n","from math import ceil\n","from tqdm import tqdm\n","from itertools import chain\n","\n","# data processing and visualization library\n","import numpy as np\n","import pandas as pd\n","#import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# image procesing library\n","#from skimage.io import imread, imshow, imread_collection, concatenate_images\n","#from skimage.transform import resize\n","#from skimage.morphology import label\n","import cv2 \n","\n","# tensorflow and keras for CNN model\n","import tensorflow as tf\n","logging.disable(logging.WARNING)\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","\n","from tensorflow.keras.models import Model, save_model, load_model, Sequential\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n","from tensorflow.keras.datasets import cifar100\n","from tensorflow.keras.utils import to_categorical\n","#from keras.utils import multi_gpu_model\n","from tensorflow.keras.preprocessing.image import Iterator, load_img, img_to_array, ImageDataGenerator\n","\n","if is_colab:\n","    from google.colab import files\n","    sys.path.append('/content/drive/MyDrive/colab/CIFAR100_Image_Classification')\n","    os.chdir('/content/drive/MyDrive/colab/CIFAR100_Image_Classification')\n","    \n","#------------------------------  Set some configuration parameters -----------------------------------#\n","args = {}\n","args['seed'] = 42\n","args['data_augmentation'] = True\n","args['training'] = True\n","args['fine_tuning'] = True\n","args['evaluation_networks'] = False\n","\n","#training arguments\n","args['batch_size'] = 32\n","args['train_epochs'] = 10\n","args['fine_tune_epochs'] = 10\n","args['validation_split'] = 0.2\n","\n","#model arguments\n","args['compare_networks'] = ['vgg19', 'resnet50', 'efficientnetb0', 'efficientnetv2', 'vit']\n","args['network'] = 'vit'\n","args['models_dir'] = 'nn_models_checkpoints'\n","\n","#optimizer arguments\n","args['optimizer'] = 'adam'\n","#args['weights'] = 'nn_models_checkpoints/best_{}.h5'.format(args['networks'][0])\n","args['learning_rate'] = 0.001\n","args['decay'] = 0.0001\n","args['loss'] = 'categorical_crossentropy'\n","\n","warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n","\n","#if args['network'] == 'efficientNetV2':   \n","#model_path = os.path.join(os.getcwd(), 'models/efficientnetv2')\n","#sys.path.append(model_path)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tjI2CcCKppQe"},"source":["## Loading the dataset\n","\n","In this project I will use the CIFAR100 dataset which is comprised of 60000 32x32 color images in 100 classes, with 600 images per class. There are 50000 training images and 10000 test images. More information is available on [CIFAR homepage](https://www.cs.toronto.edu/~kriz/cifar.html)"]},{"cell_type":"code","metadata":{"id":"32RfKAg6ppQf","executionInfo":{"status":"ok","timestamp":1630144171713,"user_tz":-60,"elapsed":10,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}}},"source":["def unpickle(file):\n","    with open(file, 'rb') as data:\n","        dataset = pickle.load(data)\n","    return dataset"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_T8_V1PqppQg","executionInfo":{"status":"ok","timestamp":1630144172068,"user_tz":-60,"elapsed":363,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}},"outputId":"51775ba2-6ac4-45bf-8644-9f1a7215add0"},"source":["#------------------------------  Load dataset using keras.dataset API -----------------------------------#\n","download_dataset = False\n","if download_dataset:\n","    train_ds, test_ds = cifar100.load_data()\n","    dataset = {}\n","    dataset['train_ds'], dataset['test_ds'] = train_ds, test_ds\n","    with open('dataset/cifar100.pickle', 'wb') as output:\n","        pickle.dump(dataset, output)\n","else:\n","    dataset = unpickle('dataset/cifar100.pickle')\n","    train_ds, test_ds = dataset['train_ds'], dataset['test_ds']\n","\n","\n","#Check train and test dataset shape\n","x_train, y_train = train_ds\n","print(\"Train dataset: x={} y={}\".format(x_train.shape, y_train.shape))\n","#Check number of classes and image shape\n","print(\"Image data shape =\", x_train.shape[1:])\n","nr_classes = len(np.unique(y_train))\n","print(\"Number of classes =\", nr_classes )\n","0\n","x_test, y_test = test_ds\n","print(\"Test dataset: x={} y={}\".format(x_test.shape, y_test.shape))\n","   "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Train dataset: x=(50000, 32, 32, 3) y=(50000, 1)\n","Image data shape = (32, 32, 3)\n","Number of classes = 100\n","Test dataset: x=(10000, 32, 32, 3) y=(10000, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"2v20CtzuppQj","executionInfo":{"status":"ok","timestamp":1630144172648,"user_tz":-60,"elapsed":583,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}},"outputId":"90c2ac83-627b-452b-e4a0-510709a52fac"},"source":["#------------------------------ Plot random images and respective labels -----------------------------------#\n","n_images = 5\n","fig, axs = plt.subplots(1, n_images, figsize=(12, 12))\n","fig.tight_layout(pad=1.0)\n","   \n","for i in range(n_images):\n","    index = random.randint(0, len(x_train))\n","    image = x_train[index].squeeze()\n","\n","    axs[i].imshow(image)\n","    axs[i].set_title(\"Label = {0}\".format(int(y_train[index])))\n","    axs[i].get_xaxis().set_visible(False)\n","    axs[i].get_yaxis().set_visible(False)\n"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x864 with 5 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"hLijVktappQk"},"source":["Analyzing the images it is clear that the images resolution is small, actually 32x32 has few pixels and therefore can be a challenge for a model to classify correctly the object. Furthermore all image has the same size so it is not required to resize the input images."]},{"cell_type":"markdown","metadata":{"id":"Q9i_voo8zLbs"},"source":["# **Data pre-processing and data augmentation**\n","The dataset output ranges from class 0 to 99. For training a model, it is easier to use a one hot encoding for the class element of each sample, in this way we transform any integer into a 100 element binary vector with a 1 for the index of the class value.\n","\n","In order to improve the model generalization for new unseen images, I will also apply data augmentation process based on random transformations."]},{"cell_type":"code","metadata":{"id":"YZGByJN1ppQo","executionInfo":{"status":"ok","timestamp":1630144172973,"user_tz":-60,"elapsed":333,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}}},"source":["#------------------------------ Categorical Transformation  -----------------------------------#\n","y_train = to_categorical(y_train, nr_classes)\n","y_test = to_categorical(y_test, nr_classes)\n","\n","\n","#------------------------------ Random data augmentation -----------------------------------#\n","if args['data_augmentation']:\n","    train_datagen = ImageDataGenerator(\n","                        rotation_range=20,\n","                        width_shift_range=0.2,\n","                        height_shift_range=0.2,\n","                        zoom_range=0.2,\n","                        horizontal_flip=True)\n","                        #validation_split=args['validation_split'])\n","    # prepare iterator\n","    train_datagen.fit(x_train)\n","    train_generator = train_datagen.flow(x_train, y_train, batch_size=args['batch_size']) #, subset='training')\n","    #validation_generator = train_datagen.flow(x_train, y_train, batch_size=args['batch_size'], subset='validation')\n","    \n","else:\n","    train_datagen = ImageDataGenerator()   \n","    train_generator = train_datagen.flow(x_train, y_train, batch_size=args['batch_size'])\n","    #validation_generator = train_datagen.flow(x_train, y_train, batch_size=args['batch_size'], subset='validation')\n","\n","test_datagen = ImageDataGenerator()   \n","test_generator = test_datagen.flow(x_test, y_test, batch_size=args['batch_size'])\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_QCnufRUl-Z5"},"source":["# **Optimizer**\n","\n","Before training it is necessary to choose an optimizer which will be responsible to adjust model parameters in order to reduce the loss funcion"]},{"cell_type":"code","metadata":{"id":"INAQZOJSphOA","executionInfo":{"status":"ok","timestamp":1630144172974,"user_tz":-60,"elapsed":6,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}}},"source":["#------------------------------ Define an optimizer -----------------------------------#\n","if 'optimizer' in args:\n","    if args['optimizer'] == 'rmsprop':\n","        optimizer = RMSprop(learning_rate=args['learning_rate'], decay=float(args['decay']))\n","    elif args['optimizer'] == 'adam':\n","        optimizer = Adam(learning_rate=args['learning_rate'], decay=float(args['decay']))\n","    elif args['optimizer'] == 'amsgrad':\n","        optimizer = Adam(learning_rate=args['learning_rate'], decay=float(args['decay']), amsgrad=True)\n","    elif args['optimizer'] == 'sgd':\n","        optimizer = SGD(learning_rate=args['learning_rate'], momentum=0.9, nesterov=True, decay=float(args['decay']))\n","else:\n","    optimizer = RMSprop(learning_rate=args['learning_rate'])"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sWLJo5_bppQs"},"source":["# **Model**\n","\n","In this project, I will use simple and light CNN models. One model follows the LeNet architecture which is built from scratch and two models are the pre-trained VGG16 and VGG19 models."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gd5VM-R-Su0_","executionInfo":{"status":"ok","timestamp":1630144179699,"user_tz":-60,"elapsed":6730,"user":{"displayName":"Granja João","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_pc30wvr--zKG1D_7yoyGBIwlFi5nbstwDsGYsxw=s64","userId":"15209494838847442457"}},"outputId":"beb97605-5c37-4c76-eae3-c677c24665e5"},"source":["from models.model_factory import make_model\n","if args['training']:\n","  #------------------------------ Make the model -----------------------------------#\n","  model = make_model(args['network'], x_train.shape[1:], nr_classes)\n","\n","  if 'weights' not in args:\n","      print('No weights passed, training from scratch')\n","  else:\n","      print('Loading weights from {}'.format(args['weights']))\n","      model.load_weights(args['weights'], by_name=True)\n","\n","  #------------------------------ Compile the model -----------------------------------#\n","  model.compile(loss=args['loss'], optimizer=optimizer, metrics=['accuracy']) \n","  model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 12, 12 to 7, 7\n","  UserWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["No weights passed, training from scratch\n","Model: \"ViT\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","tf.math.truediv (TFOpLambda) (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","tf.math.subtract (TFOpLambda (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","lambda (Lambda)              (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","vit-b32 (Functional)         (None, 100)               87532132  \n","=================================================================\n","Total params: 87,532,132\n","Trainable params: 87,532,132\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mSADHpegzLb-"},"source":["# **Training**\n","\n","This step called trainig comprises on fitting the model parameters to classify correcty the images. For that, the optimizer uses a loss function to quantify the discrepance between true and predicted labels Based on that it adjusts the model parameters to decrease the loss. Model checkpoints, EarlyStopping and Learning Rate reduce are used as callbacks to improce training efficiency."]},{"cell_type":"code","metadata":{"id":"cSWGGh32Svnu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fcf986c2-8f54-4ceb-b07f-39c9be863e5e"},"source":["if args['training']:\n","    print(\"Training model {}\".format(model.name))\n","    #------------------------------ Model check points -----------------------------------#\n","    best_model_file = '{}/best_{}.h5'.format(args['models_dir'], model.name)\n","    last_model_file = '{}/last_{}.h5'.format(args['models_dir'], model.name)\n","    model_file = '{}/model_{}.h5'.format(args['models_dir'], model.name)\n","\n","    #------------------------------ Callbacks -----------------------------------#\n","    callbacks = [\n","            # Callback to reduce the learning rate once the plateau has been reached:\n","            ReduceLROnPlateau(\n","                monitor='val_loss',\n","                min_delta=0.05,\n","                factor=1/3,\n","                patience=3,\n","                mode='auto',\n","                verbose=1,\n","                cooldown=0,\n","                min_lr=1e-8\n","            ),\n","            # Callback to stop the training once no more improvements are recorded:\n","            EarlyStopping(\n","                min_delta=0.001,\n","                verbose=1,\n","                patience=10,\n","                mode='auto',\n","                restore_best_weights=True\n","            ),\n","            # Callback to log the graph, losses and metrics into TensorBoard:\n","            TensorBoard(log_dir=\"logs/{}\".format(model.name)\n","            ),\n","            # Callback to save the best and last model specifying the epoch and val-loss in the filename:\n","            ModelCheckpoint(filepath=last_model_file, \n","                monitor='val_loss',\n","                verbose=1,\n","                mode='min',\n","                save_freq='epoch',\n","                save_best_only=False,\n","                save_weights_only=False\n","            ),\n","            ModelCheckpoint(filepath=best_model_file, \n","                monitor='val_loss',\n","                verbose=1,\n","                mode='min',\n","                save_freq='epoch',\n","                save_best_only=True,\n","                save_weights_only=False)\n","        ]\n","\n","    #------------------------------ Model Fit -----------------------------------#\n","    steps = len(x_train) // args['batch_size']\n","    history = model.fit(\n","                        train_generator,\n","                        steps_per_epoch=steps,\n","                        epochs=args['train_epochs'],\n","                        validation_data=test_generator,\n","                        callbacks=callbacks)\n","\n","    #------------------------------ Save the last model weights -----------------------------------#\n","    model.save(model_file)\n","    print(\"Saved model to disk\") "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training model ViT\n","Epoch 1/10\n","  37/1562 [..............................] - ETA: 6:47:26 - loss: 4.9426 - accuracy: 0.0203"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"szQZCm1WzprW"},"source":["# **Fine tuning**\n","\n","In the feature extraction experiment, you were only training a few layers on top of an base model. The weights of the pre-trained network were not updated during training. \n","\n","One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset."]},{"cell_type":"code","metadata":{"id":"KRobxT6d0DeF"},"source":["if args['fine_tuning']:\n","  base_model = model.get_layer(args['network'])\n","  base_model.trainable = True\n","\n","  # Let's take a look to see how many layers are in the base model\n","  print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","  # Fine-tune from this layer onwards\n","  fine_tune_at = 100\n","\n","  # Freeze all the layers before the `fine_tune_at` layer\n","  for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable =  False\n","\n","  #------------------------------ Compile the model -----------------------------------#\n","  model.compile(loss=args['loss'], optimizer=RMSprop(learning_rate=args['learning_rate']/10), metrics=['accuracy']) \n","  model.summary()\n","\n","  #------------------------------ Model Fit -----------------------------------#\n","  steps = len(x_train) // args['batch_size']\n","  total_epochs =  args['train_epochs'] + args['fine_tune_epochs']\n","  fine_tune_history = model.fit(\n","                      train_generator,\n","                      steps_per_epoch=steps,\n","                      epochs=total_epochs,\n","                      initial_epoch = history.epoch[-1],\n","                      validation_data=test_generator,\n","                      callbacks=callbacks)\n","\n","  #------------------------------ Save the last model weights -----------------------------------#\n","  model.save(model_file)\n","  print(\"Saved model to disk\")    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lI4rNBwYgXwv"},"source":["# **Visualise Model Results**"]},{"cell_type":"code","metadata":{"id":"-tUF9-UtppQx"},"source":["#------------------------------ Plot diagnostic learning curves -----------------------------------#\n","def summarize_diagnostics(history, model_name, fine_tune_history={}):\n","    # plot loss\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    if args['fine_tuning']:\n","      acc += fine_tune_history.history['accuracy']\n","      val_acc += fine_tune_history.history['val_accuracy']\n","\n","      loss += fine_tune_history.history['loss']\n","      val_loss += fine_tune_history.history['val_loss']  \n","\n","    plt.figure(figsize=(8, 8))\n","    plt.subplot(2,1,1)\n","    plt.plot(acc, label='Training Accuracy')\n","    plt.plot(val_acc, label='Validation Accuracy')\n","    plt.ylim([0.1, 1])\n","    if args['fine_tuning']:\n","      plt.plot([args['train_epochs'],args['train_epochs']],\n","          plt.ylim(), label='Start Fine Tuning')\n","    plt.legend(loc='lower right')\n","    plt.title('Training and Validation Accuracy')\n","\n","    plt.subplot(2,1,2)\n","    plt.plot(loss, label='Training Loss')\n","    plt.plot(val_loss, label='Validation Loss')\n","    #plt.ylim([0, 10])\n","    if args['fine_tuning']:\n","      plt.plot([args['train_epochs'],args['train_epochs']],\n","          plt.ylim(), label='Start Fine Tuning')\n","    plt.legend(loc='upper right')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('epoch')\n","    \n","    # save plot to file\n","    plt.savefig(\"results_\" + model_name  + '_plot.png')\n","    plt.show()\n","    plt.close()\n","\n","if args['training']:  \n","    if args['fine_tuning']:\n","      summarize_diagnostics(history, args['network'], fine_tune_history)\n","    else:\n","      summarize_diagnostics(history, args['network'])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rg9NFaPNzLcH"},"source":["# **Evaluation**\n","\n","Evaluate the model over the test dataset. We will use the last model weights and predict the class for some test images"]},{"cell_type":"code","metadata":{"id":"_HGuxPkippQy"},"source":["gc.collect\n","if args['evaluation_networks']:\n","\n","  def show_image_prediction(loaded_model, n_images):\n","    #Try out the model on an image from the test data:\n","    #plt.figure(figsize=(30, 30))\n","    fig, axs = plt.subplots(1, n_images, figsize=(15, 15))\n","    fig.tight_layout(pad=1.0)\n","\n","    # View the images\n","    for i in range(n_images):\n","        index = random.randint(0, len(x_test))\n","        image = x_test[index].squeeze()\n","        true_index = [i for i in range(nr_classes) if y_test[index][i] == 1 ][0]\n","\n","        prediction_scores = loaded_model.predict(np.expand_dims(image, axis=0))\n","        predicted_index = np.argmax(prediction_scores)\n","\n","        #image = np.add(image*128,128).astype(int)\n","        axs[i].imshow(image)\n","        axs[i].set_title(\"True Label = {0}, \\n Predicted label = {1}\".format(true_index, predicted_index))\n","        axs[i].get_xaxis().set_visible(False)\n","        axs[i].get_yaxis().set_visible(False)\n","    \n","    plt.show()\n","    plt.close()\n","\n","  #------------------------------ Predict on some test images -----------------------------------#\n","  i=1\n","\n","  for network in args['compare_networks']:\n","      print(\"----------------------- model {} -----------------------\".format(network))\n","\n","\n","      #plt.subplot(1, len(args['networks']), i)\n","      #Load last model parameters\n","      last_model_file = '{}/last_{}.h5'.format(args['models_dir'], network)\n","      best_model_file = '{}/best_{}.h5'.format(args['models_dir'], network)\n","      model_file = '{}/model_{}.h5'.format(args['models_dir'], network)\n","\n","      #Load the model\n","      loaded_model = load_model(model_file)\n","      print(\"Loaded model {} from disk\".format(model_file))\n","      loaded_model.compile(loss=args['loss'], optimizer=optimizer, metrics=['accuracy']) \n","\n","      #Try out the model on an image from the test data:\n","      show_image_prediction(loaded_model,8)\n","\n","      #------------------------------ Evaluate model on testing dataset -----------------------------------#\n","      #_, acc = loaded_model.evaluate(x_train, y_train, verbose=0)\n","      #print(\"Training accuracy of model {0} = {1}\".format(loaded_model.name, acc))\n","      _, acc = loaded_model.evaluate(x_test, y_test, verbose=0)\n","      print(\"Testing accuracy of model {0} = {1}\".format(loaded_model.name, acc)) \n","\n","      #------------------------------ Plot all model results -----------------------------------#\n","      # save plot to file\n","      filename = \"accuracy_\" + network + '_plot.png'\n","      im = cv2.imread(filename)\n","      plt.imshow(im)\n","      plt.title(\"Accuray Results of model {}\".format(network))\n","      i = i + 1\n","\n","      plt.show()\n","  plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GfrD3I1TYU8L"},"source":["Comparing the results obtained from the three models *LeNet*, *VGG16* and *VGG19*, it is possible to conclude the model with the best result is *VGG16* followed by *VGG19*. Indeed *VGG16* has the highest accuracy evaluated on testing dataset. Due to reduced capacity, *LeNet* starts overfiting earlier, actually the fine-tuning process didn't improve model results."]},{"cell_type":"markdown","metadata":{"id":"K6ajPGnahFrv"},"source":["**Conclusion**\n","\n","In this project I built from scratch a simple LeNet model and used 2 pre-trained models, VGG16 and VGG19. I train all models and evaluate the results against the CIFAR10 testing dataset. Taking into account the accuracy, the best model for this dataset was VGG16. \n","\n","So in this project, I applied several workflow steps to train a deep learning model on the image classification problem. In sume the steps were: pre-processing the input data, apply data-augmentation, build a CNN model, use pre-trained models, train a model, fine-tuning the model and evaluate the model. \n","\n","I used transfer learning technique on VGG16 and VGG19 models which is usefull when our dataset is not so large like in this case. The models accuracy on testing dataset is around 81/83% which are good results. \n","\n","For future work, I could apply better data augmentation in order to avoid overfitting as well as regularization techniques like L1 or L2. "]},{"cell_type":"code","metadata":{"id":"3Q9aWqIvhGMm"},"source":[""],"execution_count":null,"outputs":[]}]}